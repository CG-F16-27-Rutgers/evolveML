__author__ = 'abhishekchoudhary'import osimport pandas as pdfrom pyspark.mllib.feature import HashingTF, IDF, Vectorsfrom pyspark.mllib.classification import NaiveBayesfrom pyspark.mllib.regression import LabeledPointfrom pyspark import SparkContextfrom nltk.corpus import stopwords# from py4j.java_gateway import JavaGateway# from py4j.protocol import Py4JJavaError, Py4JErrordatafiles = [{'emo': 'Sad', 'name': "/negative.csv"}, {'emo': 'Happy', 'name': "/positive.csv"}             # {'emo': 'Angry', 'name': "/anger.csv"}, {'emo': "Happy", 'name': "/Happy.csv"}]BASE_DATA_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'data'))stopset = set(stopwords.words('english'))class Sentiment(object):    def readFile(self, filepath, header="tweets"):        # bigramData = sc.textFile(contentFile).cache()        return pd.read_csv(BASE_DATA_PATH + filepath, names=[header],                           header=0)    def extractData(self):        htf = HashingTF()        pos_statements = []        neg_statements = []        for value in datafiles:            emo = value['emo']            name = value['name']            read = self.readFile(name)            read['emo'] = emo            if emo == 'Happy':                words = [pos_statements.append(statement.lower().strip()) for statement in read['tweets']]            else:                words = [neg_statements.append(statement.lower().strip()) for statement in read['tweets']]        sparseList = []        for statement in neg_statements:            sparseList.append(LabeledPoint(2.0, htf.transform(word for word in statement.split() if word.lower() not in stopset)))        # sparseList.append(LabeledPoint(0.0, htf.transform(str.split())))        for statement in pos_statements:            sparseList.append(LabeledPoint(1.0, htf.transform(word for word in statement.split() if word.lower() not in stopset)))            # print "statement%s htf %s"%(trs,trs)        model = NaiveBayes.train(sc.parallelize(sparseList),1.0)        print "Modelling1 ", model.predict(htf.transform("it rains a lot in london".split()))        print "Modelling2 ", model.predict(htf.transform("my life is so good , I am loving every moment of it".split()))        print "Modelling3 ", model.predict(htf.transform("you are a very bad and terrorism and evil killing children".split()))        print "Modelling4 ", model.predict(htf.transform("that was so wrong he did not forget about the bullshit".split()))        print "Modelling5 ", model.predict(htf.transform("Unfortunately the code isn\'t open source".split()))        # print sparseListsc = SparkContext()sentiment = Sentiment()sentiment.extractData()